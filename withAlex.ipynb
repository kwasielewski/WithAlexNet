{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1qNdwaW4xo5"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kyLwVAR5A-6",
        "outputId": "fc0d6de9-ccf9-48e2-f342-9ce116b013dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.version' from '/usr/local/lib/python3.7/dist-packages/torch/version.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYkQPEfh5INo",
        "outputId": "7c142815-bd27-4a16-8cd6-d5be023f3d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "myNN = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "myNN.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCyLniJu5rKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a2f133-80a5-4011-d382-bbde5b97943b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "input_image = Image.open(\"./input.jpg\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_transformed = preprocess(input_image)\n",
        "print(input_transformed.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hilkTgHty8Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQohEUfR70ZH",
        "outputId": "dc1adea6-4e86-4252-f96e-c674844b4408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#substitute the last layer\n",
        "#probably saving wont work\n",
        "#copy needed\n",
        "originalLastLayer = myNN.classifier._modules['6']\n",
        "originalLastLayer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7GwG-M6hGYn",
        "outputId": "502eeac0-d697-4e66-f12c-cf1290865bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in myNN.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Freezing params"
      ],
      "metadata": {
        "id": "Pa4-uZf27wjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYEODTH-8ofU",
        "outputId": "a6da6f70-8025-4a85-ec9d-fa70d25951f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "myNewLayer = torch.nn.Linear(in_features=4096, out_features=6, bias=True)\n",
        "\n",
        "\n",
        "myNN.classifier =  torch.nn.Sequential(*list(myNN.classifier.children())[:-1])\n",
        "#myNN.classfier._modules['6'] = myNewLayer\n",
        "myNN\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myNN.classifier._modules['6'] = myNewLayer\n",
        "myNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXo3JpHS1mqv",
        "outputId": "3429754f-0bd9-42e6-feff-c04d2c8b8870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myNN.classifier._modules['7'] = torch.nn.Softmax(dim=1)"
      ],
      "metadata": {
        "id": "uyqNVFXv2waD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myNN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g6YkINx-A1f",
        "outputId": "dc9d4826-ca44-465a-ceff-f1f86092f1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
              "    (7): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unsqueeze(input_transformed, 0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqdrXaIj-lxt",
        "outputId": "6b091b6b-7d75-41f9-ade4-c14267963662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myNN(torch.unsqueeze(input_transformed, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9FBSGc-Fw8",
        "outputId": "7c9d4965-2af8-4d6e-98ed-ea1b6deb73b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1719, 0.0368, 0.2967, 0.0961, 0.1631, 0.2353]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(myNN(torch.unsqueeze(input_transformed, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuXOtOcRBTX3",
        "outputId": "8bc69d83-18bf-4bf9-b98f-403167e59c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5vE_wWb-RyK"
      },
      "outputs": [],
      "source": [
        "#TODO freeze the old net, train new layer with cross entropy loss, what is gcp???\n",
        "#kaggle -> it has nice online machine\n",
        "#NEEDED: read data with dataloader\n",
        "#To try: add GPU\n",
        "#jain = ja + nein\n",
        "#AWS sagemaker\n",
        "#Do not mix pandas/numpy with GPU solutions -> causes movement of data\n",
        "#Add confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = \"./drive/MyDrive/CNN/flowers/flowers/flower_photos/\""
      ],
      "metadata": {
        "id": "ouyuWTMmi3a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqcMsvUr_OTJ",
        "outputId": "04257236-afb5-407a-8d65-ad3e4e108fba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "originalLastLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viNj3PpD_oME",
        "outputId": "138cc370-99d7-4955-b350-6886c93f8303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.8789, 0.8104, 0.7419,  ..., 0.6563, 0.6734, 0.6906],\n",
            "         [0.8961, 0.8618, 0.8104,  ..., 0.6734, 0.7077, 0.7248],\n",
            "         [0.9646, 0.9303, 0.8961,  ..., 0.7077, 0.7419, 0.7419],\n",
            "         ...,\n",
            "         [0.4166, 0.3994, 0.3823,  ..., 0.3481, 0.3823, 0.3652],\n",
            "         [0.3994, 0.3823, 0.3823,  ..., 0.3309, 0.3481, 0.3481],\n",
            "         [0.3652, 0.3652, 0.3823,  ..., 0.3309, 0.3138, 0.3309]],\n",
            "\n",
            "        [[1.0280, 0.9580, 0.8880,  ..., 0.8004, 0.8179, 0.8354],\n",
            "         [1.0455, 1.0105, 0.9755,  ..., 0.8179, 0.8529, 0.8704],\n",
            "         [1.1155, 1.0805, 1.0630,  ..., 0.8529, 0.8880, 0.8880],\n",
            "         ...,\n",
            "         [0.5378, 0.5203, 0.5028,  ..., 0.5028, 0.5378, 0.5203],\n",
            "         [0.5203, 0.5028, 0.5028,  ..., 0.4853, 0.5028, 0.5028],\n",
            "         [0.4853, 0.4853, 0.5028,  ..., 0.4853, 0.4678, 0.4853]],\n",
            "\n",
            "        [[1.3851, 1.3154, 1.2282,  ..., 1.0191, 1.0365, 1.0539],\n",
            "         [1.4025, 1.3677, 1.3154,  ..., 1.0365, 1.0714, 1.0888],\n",
            "         [1.4722, 1.4374, 1.4025,  ..., 1.0714, 1.1062, 1.1062],\n",
            "         ...,\n",
            "         [0.8448, 0.8274, 0.8099,  ..., 0.8099, 0.8448, 0.8274],\n",
            "         [0.8274, 0.8099, 0.8099,  ..., 0.7925, 0.8099, 0.8099],\n",
            "         [0.7925, 0.7925, 0.8099,  ..., 0.8099, 0.7751, 0.7925]]]), 0)\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7ff3ee70ee90>\n"
          ]
        }
      ],
      "source": [
        "train_ds = datasets.ImageFolder(DATAPATH+\"train\", transform=preprocess)\n",
        "print(train_ds[0])\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=10, shuffle=True)\n",
        "print(train_dl)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(myNN.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "DQ5mSFe_sePZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numEpochs = 1"
      ],
      "metadata": {
        "id": "YclQaUcQB5HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dl, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = myNN(inputs)\n",
        "        #print(labels)\n",
        "        #print(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 20 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDnlXPdbpv0x",
        "outputId": "fb6aa87b-bafb-43fe-ce11-4d0ee02f8bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    20] loss: 0.013\n",
            "[1,    40] loss: 0.013\n",
            "[1,    60] loss: 0.012\n",
            "[1,    80] loss: 0.012\n",
            "[1,   100] loss: 0.012\n",
            "[1,   120] loss: 0.012\n",
            "[1,   140] loss: 0.012\n",
            "[1,   160] loss: 0.012\n",
            "[1,   180] loss: 0.012\n",
            "[1,   200] loss: 0.012\n",
            "[1,   220] loss: 0.012\n",
            "[1,   240] loss: 0.012\n",
            "[1,   260] loss: 0.012\n",
            "[1,   280] loss: 0.012\n",
            "[1,   300] loss: 0.012\n",
            "[1,   320] loss: 0.012\n",
            "[1,   340] loss: 0.012\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add accuracy, test set, confusion matrix"
      ],
      "metadata": {
        "id": "dqcO9cCw1SOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = datasets.ImageFolder(DATAPATH+\"test\", transform=preprocess)\n",
        "\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=10, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "uhO5mmnfC0Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "confussion = np.zeros((5,5))\n",
        "\n",
        "# iterate over test data\n",
        "for inputs, labels in test_dl:\n",
        "    output = myNN(inputs) # Feed Networ        \n",
        "    for i, pred in enumerate(output):\n",
        "        #print(labels[i])\n",
        "        #print(torch.argmax(output[i]))\n",
        "        confussion[labels[i]][torch.argmax(output[i])] +=1\n",
        "\n",
        "print(confussion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLmxY006C_QS",
        "outputId": "e6e6012b-de5b-4410-fbd9-72ccb4b7f250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9. 0. 1. 0. 0.]\n",
            " [0. 9. 0. 0. 1.]\n",
            " [0. 1. 6. 0. 3.]\n",
            " [1. 0. 0. 9. 0.]\n",
            " [2. 0. 1. 0. 7.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.matshow(confussion)"
      ],
      "metadata": {
        "id": "HwCx-g8sE_ES"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "withAlex.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}